{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://github.com/tdunning/python-llr\n",
    "\n",
    "def cmp(a, b):\n",
    "    return (a > b) - (a < b) \n",
    "\n",
    "from collections import Counter \n",
    "import math\n",
    "from functools import reduce\n",
    "\n",
    "def denormEntropy(counts):\n",
    "    '''Computes the entropy of a list of counts scaled by the sum of the counts. If the inputs sum to one, this is just the normal definition of entropy'''\n",
    "    counts = list(counts)\n",
    "    total = float(sum(counts))\n",
    "    # Note tricky way to avoid 0*log(0)\n",
    "    return -sum([k * math.log(k/total + (k==0)) for k in counts])\n",
    "\n",
    "def llr_2x2(k11, k12, k21, k22):\n",
    "    '''Special case of llr with a 2x2 table'''\n",
    "    return 2 * abs(denormEntropy([k11+k12, k21+k22]) +\n",
    "                denormEntropy([k11+k21, k12+k22]) -\n",
    "                denormEntropy([k11, k12, k21, k22]))\n",
    "\n",
    "def llr_root(k11, k12, k21, k22):\n",
    "    '''Computes a score for a 2x2 contingency table, but then adds a sign according to whether k11 is larger (result is positive) or smaller (result is negative) than might be expected. The magnitude of the result can be roughly interpreted on a scale similar to standard deviations'''\n",
    "    row = k11 + k21\n",
    "    total = (k11 + k12 + k21 + k22)\n",
    "    sign = cmp(float(k11) / (k11 + k12), float(row) / total)\n",
    "    return math.copysign(math.sqrt(llr_2x2(k11, k12, k21, k22)), sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 1, 1],\n",
       "       [1, 1, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0],\n",
       "       [1, 1, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rawdata = np.array([\n",
    "    [5,5,0,0,0,0],\n",
    "    [0,0,5,5,0,0],\n",
    "    [0,0,0,0,5,5],\n",
    "    [0,1,5,5,5,0],\n",
    "    [1,1,5,0,5,5],\n",
    "    [5,5,0,5,1,1],\n",
    "    [5,0,0,5,0,1],\n",
    "    [5,5,5,0,1,0]\n",
    "    ])\n",
    "    \n",
    "likes = np.array([[1 if x == 5 else 0 for x in row] for row in rawdata])\n",
    "likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 3, 1, 2, 0, 0],\n",
       "       [3, 3, 1, 1, 0, 0],\n",
       "       [1, 1, 4, 2, 2, 1],\n",
       "       [2, 1, 2, 4, 1, 0],\n",
       "       [0, 0, 2, 1, 3, 2],\n",
       "       [0, 0, 1, 0, 2, 2]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooccurrence_matrix = np.dot(likes.transpose(), likes)\n",
    "cooccurrence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 1, 2, 0, 0],\n",
       "       [3, 0, 1, 1, 0, 0],\n",
       "       [1, 1, 0, 2, 2, 1],\n",
       "       [2, 1, 2, 0, 1, 0],\n",
       "       [0, 0, 2, 1, 0, 2],\n",
       "       [0, 0, 1, 0, 2, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.fill_diagonal(cooccurrence_matrix, 0)\n",
    "cooccurrence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, array([6, 5, 7, 6, 5, 3]), 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = cooccurrence_matrix.shape[0]\n",
    "sums = np.array([row.sum() for row in cooccurrence_matrix[:,0:size]])\n",
    "total = sums.sum()\n",
    "size, sums, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 -1.671630571360789\n",
      "0 1 2.033620752749888\n",
      "0 2 -0.4444608330501006\n",
      "0 3 0.7721212322079151\n",
      "0 4 -1.5102415112211136\n",
      "0 5 -1.1470194399358786\n",
      "1 0 2.033620752749888\n",
      "1 1 -1.3647652539835755\n",
      "1 2 -0.19582196118803194\n",
      "1 3 1.1920928955078125e-07\n",
      "1 4 -1.3647652539835755\n",
      "1 5 -1.0369825130804433\n",
      "2 0 -0.4444608330501006\n",
      "2 1 -0.19582196118803194\n",
      "2 2 -1.9932131287507497\n",
      "2 3 0.5199643772432565\n",
      "2 4 0.8219975087691875\n",
      "2 5 0.4161095064184788\n",
      "3 0 0.7721212322079151\n",
      "3 1 1.1920928955078125e-07\n",
      "3 2 0.5199643772432565\n",
      "3 3 -1.671630571360789\n",
      "3 4 1.1920928955078125e-07\n",
      "3 5 -1.1470194399358786\n",
      "4 0 -1.5102415112211136\n",
      "4 1 -1.3647652539835755\n",
      "4 2 0.8219975087691875\n",
      "4 3 1.1920928955078125e-07\n",
      "4 4 -1.3647652539835755\n",
      "4 5 2.027561328129231\n",
      "5 0 -1.1470194399358786\n",
      "5 1 -1.0369825130804433\n",
      "5 2 0.4161095064184788\n",
      "5 3 -1.1470194399358786\n",
      "5 4 2.027561328129231\n",
      "5 5 -0.7885438972362838\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, size):\n",
    "    for j in range(0, size):\n",
    "        a_b = cooccurrence_matrix[i,j].tolist()\n",
    "        a_not_b = (sums[i] - a_b).tolist()\n",
    "        b_not_a = (sums[j] - a_b).tolist()\n",
    "        not_ab = (total - (a_b + sums[i] + sums[j])).tolist()\n",
    "        print(i, j, llr_root(a_b, a_not_b, b_not_a, not_ab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise\n",
    "\n",
    "So far we've used the \"people who liked A were unusually likely to like B\" statistics to make predictions, but we've ignored the information we have about dislikes. Can you find a way to improve the results by leveraging the 1 values in the rawdata (the dislikes)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
